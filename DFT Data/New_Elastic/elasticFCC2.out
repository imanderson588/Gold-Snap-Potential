MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found

     Program PWSCF v.7.0 starts on  3Dec2023 at  8:52:19 

     This program is part of the open-source Quantum ESPRESSO suite
     for quantum simulation of materials; please cite
         "P. Giannozzi et al., J. Phys.:Condens. Matter 21 395502 (2009);
         "P. Giannozzi et al., J. Phys.:Condens. Matter 29 465901 (2017);
         "P. Giannozzi et al., J. Chem. Phys. 152 154105 (2020);
          URL http://www.quantum-espresso.org", 
     in publications or presentations arising from this work. More details at
     http://www.quantum-espresso.org/quote

     Parallel version (MPI), running on    10 processors

     MPI processes distributed on     1 nodes
     K-points division:     npool     =       2
     R & G space division:  proc/nbgrp/npool/nimage =       5
     77966 MiB available memory on the printing compute node when the environment starts
 
     Reading input from elasticFCC2.in
Warning: card &CELL ignored
Warning: card / ignored

     Current dimensions of program PWSCF are:
     Max number of different atomic species (ntypx) = 10
     Max number of k-points (npk) =  40000
     Max angular momentum in pseudopotentials (lmaxx) =  4
     file Au.pbe-n-kjpaw_psl.1.0.0.UPF: wavefunction(s)  6S 5D renormalized

     Subspace diagonalization in iterative solution of the eigenvalue problem:
     one sub-group per band group will be used
     scalapack distributed-memory algorithm (size of sub-group:  2*  2 procs)

 
     Parallelization info
     --------------------
     sticks:   dense  smooth     PW     G-vecs:    dense   smooth      PW
     Min         601     208     62                24139     4936     809
     Max         602     209     64                24142     4938     810
     Sum        3007    1043    315               120699    24685    4049
 
     Using Slab Decomposition
 


     bravais-lattice index     =            0
     lattice parameter (alat)  =       8.2270  a.u.
     unit-cell volume          =     517.0774 (a.u.)^3
     number of atoms/cell      =            4
     number of atomic types    =            1
     number of electrons       =        44.00
     number of Kohn-Sham states=           26
     kinetic-energy cutoff     =      50.0000  Ry
     charge density cutoff     =     576.0000  Ry
     scf convergence threshold =      1.0E-06
     mixing beta               =       0.7000
     number of iterations used =            8  plain     mixing
     Exchange-correlation= SLA  PW   PBX  PBC
                           (   1   4   3   4   0   0   0)

     celldm(1)=   8.226968  celldm(2)=   0.000000  celldm(3)=   0.000000
     celldm(4)=   0.000000  celldm(5)=   0.000000  celldm(6)=   0.000000

     crystal axes: (cart. coord. in units of alat)
               a(1) = (   1.000000   0.000000   0.000000 )  
               a(2) = (   0.000000   0.968275   0.000000 )  
               a(3) = (   0.000000   0.000000   0.959042 )  

     reciprocal axes: (cart. coord. in units 2 pi/alat)
               b(1) = (  1.000000  0.000000  0.000000 )  
               b(2) = (  0.000000  1.032765  0.000000 )  
               b(3) = (  0.000000  0.000000  1.042708 )  


     PseudoPot. # 1 for Au read from file:
     ./Au.pbe-n-kjpaw_psl.1.0.0.UPF
     MD5 check sum: 4db85c736373c707a97ce4c36c2a9d23
     Pseudo is Projector augmented-wave + core cor, Zval = 11.0
     Generated using &quot;atomic&quot; code by A. Dal Corso  v.6.3
     Shape of augmentation charge: PSQ
     Using radial grid of 1279 points,  6 beta functions with: 
                l(1) =   0
                l(2) =   0
                l(3) =   1
                l(4) =   1
                l(5) =   2
                l(6) =   2
     Q(r) pseudized with 0 coefficients 


     atomic species   valence    mass     pseudopotential
        Au            11.00   196.96657     Au( 1.00)

     No symmetry found



   Cartesian axes

     site n.     atom                  positions (alat units)
         1           Au  tau(   1) = (   0.0000000   0.0000000   0.0000000  )
         2           Au  tau(   2) = (   0.0000000   0.4781686   0.4781686  )
         3           Au  tau(   3) = (   0.4781686   0.0000000   0.4781686  )
         4           Au  tau(   4) = (   0.4781686   0.4781686   0.0000000  )

     number of k points=   260  Gaussian smearing, width (Ry)=  0.0020

     Number of k-points >= 100: set verbosity='high' to print them.

     Dense  grid:   120699 G-vectors     FFT dimensions: (  64,  64,  64)

     Smooth grid:    24685 G-vectors     FFT dimensions: (  40,  36,  36)

     Estimated max dynamical RAM per process >      84.52 MB

     Estimated total dynamical RAM >     815.72 MB

     Initial potential from superposition of free atoms

     starting charge      43.9996, renormalised to      44.0000
     Starting wfcs are   36 randomized atomic wfcs
     Checking if some PAW data can be deallocated... 

     total cpu time spent up to now is        2.2 secs

     Self-consistent Calculation

     iteration #  1     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     ethr =  1.00E-02,  avg # of iterations =  2.9

     Threshold (ethr) on eigenvalues was too large:
     Diagonalizing with lowered threshold

     Davidson diagonalization with overlap
     ethr =  2.96E-04,  avg # of iterations =  4.0

     total cpu time spent up to now is       10.2 secs

     total energy              =   -3100.47921237 Ry
     estimated scf accuracy    <       0.18141819 Ry

     iteration #  2     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     ethr =  4.12E-04,  avg # of iterations =  3.3

     total cpu time spent up to now is       14.7 secs

     total energy              =   -3100.53975093 Ry
     estimated scf accuracy    <       0.02199204 Ry

     iteration #  3     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     ethr =  5.00E-05,  avg # of iterations =  4.4

     total cpu time spent up to now is       19.1 secs

     total energy              =   -3100.54416117 Ry
     estimated scf accuracy    <       0.00172875 Ry

     iteration #  4     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     c_bands:  1 eigenvalues not converged
     c_bands:  1 eigenvalues not converged
     c_bands:  1 eigenvalues not converged
     c_bands:  1 eigenvalues not converged
     ethr =  3.93E-06,  avg # of iterations =  6.1

     total cpu time spent up to now is       25.0 secs

     total energy              =   -3100.54538123 Ry
     estimated scf accuracy    <       0.00095427 Ry

     iteration #  5     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     c_bands:  1 eigenvalues not converged
     ethr =  2.17E-06,  avg # of iterations =  2.9

     total cpu time spent up to now is       29.3 secs

     total energy              =   -3100.54540389 Ry
     estimated scf accuracy    <       0.00081145 Ry

     iteration #  6     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     ethr =  1.84E-06,  avg # of iterations =  1.2

     total cpu time spent up to now is       32.2 secs

     total energy              =   -3100.54542881 Ry
     estimated scf accuracy    <       0.00014633 Ry

     iteration #  7     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     ethr =  3.33E-07,  avg # of iterations =  3.8

     total cpu time spent up to now is       36.6 secs

     total energy              =   -3100.54545400 Ry
     estimated scf accuracy    <       0.00002016 Ry

     iteration #  8     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     ethr =  4.58E-08,  avg # of iterations =  6.1

     total cpu time spent up to now is       43.1 secs

     total energy              =   -3100.54547393 Ry
     estimated scf accuracy    <       0.00001338 Ry

     iteration #  9     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     ethr =  3.04E-08,  avg # of iterations =  1.7

     total cpu time spent up to now is       46.2 secs

     total energy              =   -3100.54547411 Ry
     estimated scf accuracy    <       0.00000253 Ry

     iteration # 10     ecut=    50.00 Ry     beta= 0.70
     Davidson diagonalization with overlap
     ethr =  5.76E-09,  avg # of iterations =  3.1

     total cpu time spent up to now is       50.3 secs

     End of self-consistent calculation

     Number of k-points >= 100: set verbosity='high' to print the bands.

     the Fermi energy is    13.3277 ev

!    total energy              =   -3100.54547448 Ry

     total all-electron energy =   -152095.929839 Ry
     estimated scf accuracy    <       0.00000033 Ry
     smearing contrib. (-TS)   =      -0.00005426 Ry
     internal energy E=F+TS    =   -3100.54542022 Ry

     The total energy is F=E-TS. E is the sum of the following terms:
     one-electron contribution =      38.55219011 Ry
     hartree contribution      =      35.24305686 Ry
     xc contribution           =    -128.13493243 Ry
     ewald contribution        =    -276.17603720 Ry
     one-center paw contrib.   =   -2770.02969756 Ry

     convergence has been achieved in  10 iterations

     Forces acting on atoms (cartesian axes, Ry/au):

     atom    1 type  1   force =    -0.01602912   -0.00486541   -0.00111998
     atom    2 type  1   force =    -0.01602973    0.00486587    0.00112246
     atom    3 type  1   force =     0.01602073   -0.00486533    0.00111472
     atom    4 type  1   force =     0.01603811    0.00486487   -0.00111721

     Total force =     0.033578     Total SCF correction =     0.000172

     Writing all to output data dir ./pwscf.save/
 
     init_run     :      1.72s CPU      1.85s WALL (       1 calls)
     electrons    :     47.31s CPU     48.19s WALL (       1 calls)
     forces       :      0.44s CPU      0.46s WALL (       1 calls)

     Called by init_run:
     wfcinit      :      1.23s CPU      1.28s WALL (       1 calls)
     potinit      :      0.14s CPU      0.20s WALL (       1 calls)
     hinit0       :      0.18s CPU      0.19s WALL (       1 calls)

     Called by electrons:
     c_bands      :     41.35s CPU     41.95s WALL (      11 calls)
     sum_band     :      4.80s CPU      4.91s WALL (      11 calls)
     v_of_rho     :      0.29s CPU      0.41s WALL (      11 calls)
     newd         :      0.26s CPU      0.28s WALL (      11 calls)
     PAW_pot      :      0.63s CPU      0.64s WALL (      11 calls)
     mix_rho      :      0.02s CPU      0.02s WALL (      11 calls)

     Called by c_bands:
     init_us_2    :      0.45s CPU      0.46s WALL (    3120 calls)
     init_us_2:cp :      0.45s CPU      0.46s WALL (    3120 calls)
     cegterg      :     34.66s CPU     35.21s WALL (    1430 calls)

     Called by *egterg:
     cdiaghg      :      5.37s CPU      5.46s WALL (    6418 calls)
     h_psi        :     23.30s CPU     23.72s WALL (    6678 calls)
     s_psi        :      1.41s CPU      1.43s WALL (    6678 calls)
     g_psi        :      0.14s CPU      0.14s WALL (    5118 calls)

     Called by h_psi:
     h_psi:calbec :      1.64s CPU      1.67s WALL (    6678 calls)
     vloc_psi     :     19.92s CPU     20.29s WALL (    6678 calls)
     add_vuspsi   :      1.60s CPU      1.62s WALL (    6678 calls)

     General routines
     calbec       :      2.18s CPU      2.22s WALL (    8628 calls)
     fft          :      0.25s CPU      0.46s WALL (     153 calls)
     ffts         :      0.02s CPU      0.04s WALL (      22 calls)
     fftw         :     21.56s CPU     21.96s WALL (  265118 calls)
     interpolate  :      0.04s CPU      0.11s WALL (      11 calls)
 
     Parallel routines
 
     PWSCF        :     50.55s CPU     53.85s WALL

 
   This run was terminated on:   8:53:13   3Dec2023            

=------------------------------------------------------------------------------=
   JOB DONE.
=------------------------------------------------------------------------------=
